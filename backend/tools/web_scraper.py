# tools/web_scraper.py
import asyncio
import json
from playwright.async_api import async_playwright


async def scrape_amazon(page, product_keyword: str, num_results: int):
    """
    Scrape product data from Amazon India.

    Args:
        page: Playwright page instance
        product_keyword: Search term
        num_results: Number of products to return

    Returns:
        List of product dicts with keys: name, image_url, current_price, summary, key_specifications, product_url, source
    """
    products_data = []
    search_url = f"https://www.amazon.in/s?k={product_keyword.replace(' ', '+')}"
    await page.goto(search_url, wait_until="domcontentloaded")
    await page.wait_for_selector('[data-component-type="s-search-result"]', timeout=15000)

    results = await page.locator('[data-component-type="s-search-result"]').all()
    results_to_process = results[:num_results] if results else []

    for result in results_to_process:
        try:
            # Name
            name_element = result.locator("h2 a span").first
            name = await name_element.inner_text() if await name_element.count() > 0 else "N/A"

            # URL
            link_element = result.locator("h2 a").first
            link = await link_element.get_attribute("href") if await link_element.count() > 0 else "N/A"
            if link and not link.startswith("http"):
                link = "https://www.amazon.in" + link

            # Price
            price = None
            price_whole = result.locator(".a-price-whole").first
            price_fraction = result.locator(".a-price-fraction").first
            if await price_whole.count() > 0 and await price_fraction.count() > 0:
                price_str = (await price_whole.inner_text()).replace(",", "") + await price_fraction.inner_text()
                try:
                    price = float(price_str)
                except ValueError:
                    price = None
            else:
                offscreen_price = result.locator(".a-offscreen").first
                if await offscreen_price.count() > 0:
                    offscreen_price_str = (await offscreen_price.inner_text()).replace("$", "").replace(",", "")
                    try:
                        price = float(offscreen_price_str)
                    except ValueError:
                        price = None

            # Image
            image_element = result.locator(".s-image").first
            image_url = await image_element.get_attribute("src") if await image_element.count() > 0 else "N/A"

            # Append
            products_data.append({
                "name": name,
                "image_url": image_url,
                "current_price": price,
                "summary": "Summary to be generated by AI agent.",
                "key_specifications": {"placeholder_spec": "Details to be determined by AI"},
                "product_url": link,
                "source": "Amazon"
            })

        except Exception as e:
            print(f"⚠️ Amazon scraping error: {e}")
            continue

    return products_data


async def scrape_flipkart(page, product_keyword: str, num_results: int):
    """
    Scrape product data from Flipkart.

    Args:
        page: Playwright page instance
        product_keyword: Search term
        num_results: Number of products to return

    Returns:
        List of product dicts similar to Amazon scraper
    """
    products_data = []
    search_url = f"https://www.flipkart.com/search?q={product_keyword.replace(' ', '+')}"
    await page.goto(search_url, wait_until="domcontentloaded")
    await page.wait_for_selector("div._1AtVbE", timeout=15000)

    results = await page.locator("div._1AtVbE").all()
    results_to_process = results[:num_results] if results else []

    for result in results_to_process:
        try:
            # Name & URL
            name_element = result.locator("a.s1Q9rs, a.IRpwTa").first
            name = await name_element.inner_text() if await name_element.count() > 0 else "N/A"
            link = await name_element.get_attribute("href") if await name_element.count() > 0 else "N/A"
            if link and not link.startswith("http"):
                link = "https://www.flipkart.com" + link

            # Price
            price = None
            price_element = result.locator("div._30jeq3").first
            if await price_element.count() > 0:
                price_str = (await price_element.inner_text()).replace("₹", "").replace(",", "")
                try:
                    price = float(price_str)
                except ValueError:
                    price = None

            # Image
            image_element = result.locator("img._396cs4, img._2r_T1I").first
            image_url = await image_element.get_attribute("src") if await image_element.count() > 0 else "N/A"

            # Append
            products_data.append({
                "name": name,
                "image_url": image_url,
                "current_price": price,
                "summary": "Summary to be generated by AI agent.",
                "key_specifications": {"placeholder_spec": "Details to be determined by AI"},
                "product_url": link,
                "source": "Flipkart"
            })

        except Exception as e:
            print(f"⚠️ Flipkart scraping error: {e}")
            continue

    return products_data


def scrape_ecommerce_site(product_keyword: str, num_results: int = 5, source: str = "both", tracker=None, session_id=None):
    """
    Scrape products from Amazon, Flipkart, or both with progress tracking.

    Args:
        product_keyword: Search keyword
        num_results: Number of results per site
        source: 'amazon', 'flipkart', or 'both'
        tracker: ScrapingTracker instance for progress updates
        session_id: Session ID for tracking

    Returns:
        List of product dicts
    """
    async def _scrape_async():
        products_data = []

        async with async_playwright() as p:
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()

            if source.lower() == "amazon":
                if tracker and session_id:
                    tracker.update_status(session_id, "scraping_amazon", "amazon")
                products_data = await scrape_amazon(page, product_keyword, num_results)
                if tracker and session_id:
                    tracker.store_products(session_id, products_data, "amazon")
                    tracker.update_product_count(session_id, amazon_count=len(products_data))
                    
            elif source.lower() == "flipkart":
                if tracker and session_id:
                    tracker.update_status(session_id, "scraping_flipkart", "flipkart")
                products_data = await scrape_flipkart(page, product_keyword, num_results)
                if tracker and session_id:
                    tracker.store_products(session_id, products_data, "flipkart")
                    tracker.update_product_count(session_id, flipkart_count=len(products_data))
                    
            elif source.lower() == "both":
                # Scrape Amazon first
                if tracker and session_id:
                    tracker.update_status(session_id, "scraping_amazon", "amazon")
                amazon_results = await scrape_amazon(page, product_keyword, num_results)
                if tracker and session_id:
                    tracker.store_products(session_id, amazon_results, "amazon")
                
                # Scrape Flipkart second
                if tracker and session_id:
                    tracker.update_status(session_id, "scraping_flipkart", "flipkart")
                flipkart_results = await scrape_flipkart(page, product_keyword, num_results)
                if tracker and session_id:
                    tracker.store_products(session_id, flipkart_results, "flipkart")
                    tracker.update_product_count(session_id, amazon_count=len(amazon_results), flipkart_count=len(flipkart_results))
                
                products_data = amazon_results + flipkart_results
            else:
                raise ValueError("Invalid source. Choose 'amazon', 'flipkart', or 'both'.")

            await browser.close()
            
            # Mark as processing if we have a tracker
            if tracker and session_id:
                tracker.update_status(session_id, "processing", "processing")
                
        return products_data

    return asyncio.run(_scrape_async())


# --- Test Scraper ---
if __name__ == "__main__":
    test_keywords = "gaming keyboard"
    print("Testing Amazon only:")
    print(json.dumps(scrape_ecommerce_site(test_keywords, 2, "amazon"), indent=2))

    print("\nTesting Flipkart only:")
    print(json.dumps(scrape_ecommerce_site(test_keywords, 2, "flipkart"), indent=2))

    print("\nTesting Both Amazon + Flipkart:")
    print(json.dumps(scrape_ecommerce_site(test_keywords, 2, "both"), indent=2))
